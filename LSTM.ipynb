{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"42749267-c5c4-412a-98c5-e2fc645bfea3"},"source":["import numpy as np\n","import pandas as pd\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import math\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","mm = MinMaxScaler()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"98651775-bf67-491c-be4f-d444fcd7a5e8"},"source":["class PriceDataset(Dataset):\n","\n","    def __init__(self, data, window_size, scaler, days_after):\n","        self.data = scaler.transform(data)\n","        self.window_size = window_size\n","        self.days_after = days_after\n","\n","        self.x, self.y = self.getSeriesData(self.data, window_size, days_after)\n","\n","\n","    def __len__(self):\n","        return len(self.data) - self.window_size - self.days_after\n","\n","\n","    def __getitem__(self, idx):\n","        return self.x[idx], self.y[idx]\n","\n","\n","    # Learning Period, Prediction Period\n","    def getSeriesData(self, data, window_size, days_after):\n","        n_pairs = len(data) - window_size - days_after\n","        xlist = [data[i:i + window_size] for i in range(n_pairs)]\n","        ylist = [data[i + window_size + days_after] for i in range(n_pairs)]\n","\n","        x = torch.Tensor(xlist)\n","        y = torch.Tensor(ylist)\n","\n","        return x, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3f8a948d-bcd6-4c05-ab29-856f513ac8be"},"source":["df = pd.read_csv('data_final.csv')\n","df = df.drop(['time'], axis = 1)\n","\n","df.head(2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9MLXBkN9-3jX"},"source":["train, test = train_test_split(df, test_size = 0.4, shuffle = False)\n","valid, test = train_test_split(test, test_size = 0.5, shuffle = False)\n","\n","window_size = 30 # Set how many days to learn\n","days_after = 3 # Set the number of days for price forecasting\n","batch_size = 64\n","\n","days_after = (days_after - 1)\n","\n","mm.fit(train)    \n","train_dataset = PriceDataset(train, window_size, mm, days_after) \n","valid_dataset = PriceDataset(valid, window_size, mm, days_after) \n","test_dataset  = PriceDataset(test, window_size, mm, days_after) \n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle = False, drop_last = True)\n","valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle = False, drop_last = True)\n","test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle = False, drop_last = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"466a2b26-37ac-4537-9ae7-884b3e31db5d"},"source":["class LSTM1(nn.Module): \n","    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length, dropout): \n","        super(LSTM1, self).__init__() \n","        self.num_classes = num_classes \n","        self.num_layers = num_layers \n","        self.input_size = input_size \n","        self.hidden_size = hidden_size \n","        self.seq_length = seq_length \n","\n","        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, batch_first = True) # LSTM\n","        self.fc_1 = nn.Linear(hidden_size, 128) # Fully connected 1 \n","        self.fc = nn.Linear(128, num_classes) # Fully connected last layer \n","        self.relu = nn.ReLU() \n","       \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    \n","    def forward(self,x): \n","\n","        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) # Hidden State \n","        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) # Internal State \n","        # Propagate input through LSTM \n","\n","        output, (hn, cn) = self.lstm(x, (h_0, c_0)) # LSTM with input, hidden, and internal state \n","\n","        hn = hn.view(-1, self.hidden_size) # Reshaping the data for Dense layer next \n","        out = self.relu(hn) \n","        out = self.fc_1(out) # First Dense \n","        out = self.relu(out) # Relu \n","        out = self.fc(out) # Final Output \n","        return out  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5769da35-970c-44f5-bead-a01043772b17","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629997742213,"user_tz":-540,"elapsed":414,"user":{"displayName":"이도영","photoUrl":"","userId":"16691859806818727656"}},"outputId":"708f74bd-919c-439f-9824-b176322309d3"},"source":["# Adjust Parameters\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","epochs = 300\n","learning_rate = 0.001 \n","dropout = 0.01\n","\n","input_size = 68 # Number of Features\n","hidden_size = 100\n","num_layers = 1 \n","\n","clip = 5 # Gradient Clipping\n","counter = 0\n","print_every = 500\n","\n","num_classes = 1 # Number of Output Classes \n","model = LSTM1(num_classes, input_size, hidden_size, num_layers, window_size, dropout)\n","\n","model.to(device)\n","\n","loss_function = torch.nn.MSELoss() # Mean-squared Error for Regression\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # Adam Optimizer"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"364911b5-22e8-4965-b4c7-d7ab635da110"},"source":["model.train()\n","for e in range(epochs):\n","    running_loss = 0\n","    for x, y in train_loader:\n","        x = x.to(device)\n","        y = y.to(device)\n","        y = y[:, 0].unsqueeze(1)\n","        model.zero_grad()\n","\n","        output = model(x)\n","        \n","        loss = loss_function(output.squeeze(), y.float())\n","        loss.backward()\n","        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","        nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","        \n","        # Loss Stats\n","        if counter % print_every == 0:\n","          \n","            # Get validation loss\n","            val_losses = []\n","            model.eval()\n","\n","            for inputs, labels in valid_loader:\n","                labels = labels[:, 0].unsqueeze(1)\n","\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                output = model(inputs)\n","                val_loss = loss_function(output.squeeze(), labels.float())\n","\n","                val_losses.append(val_loss.item())\n","\n","            model.train()\n","\n","            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n","                  \"Loss: {:.6f}...\".format(loss.item()),\n","                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MWBPkBgY0Kqg"},"source":["test_RMSE = []\n","outputs = []\n","actual = []\n","\n","model.eval()\n","\n","sum = 0\n","number = 0\n","\n","for inputs, labels in test_loader: \n","  labels = labels[:, 0].unsqueeze(1)\n","  inputs, labels = inputs.to(device), labels.to(device)\n","  output = model(inputs)\n","\n","  outputs.extend(output[:, 0].view(-1).detach().cpu().numpy())\n","  actual.extend(labels.view(-1).detach().cpu().numpy())\n","\n","  test_loss = loss_function(output.squeeze(), labels.float())\n","  test_loss = torch.sqrt(test_loss)\n","  test_RMSE.append(test_loss.item())\n","\n","  sum += np.mean(test_RMSE)\n","  number += 1\n","\n","  print(np.mean(test_RMSE))\n","\n","average = sum / number\n","print(\"\\n average : {} \\n\".format(average)) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JGTmEbHDxK9j"},"source":["import matplotlib.pyplot as plt\n","\n","fix, ax = plt.subplots()\n","ax.plot(actual, label = 'actul')\n","ax.plot(outputs, label = 'prediction')\n","\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]}]}